{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Injury Classification CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN1QLOCCyhXW+XGtxRmFPt2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "917dc8ca599f446b8b0dc167c4291d5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_65e00ba867dc477e9d2c3f1d5639b64a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b4a85e1b17794161a5e1d3c265e64a7c",
              "IPY_MODEL_eed22318adf746ab97829f7e7a5cf0b3"
            ]
          }
        },
        "65e00ba867dc477e9d2c3f1d5639b64a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b4a85e1b17794161a5e1d3c265e64a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e42193319cf1415a851da0b429dd503d",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553433881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553433881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e855c8dbf80428b81d44c6e11a2a026"
          }
        },
        "eed22318adf746ab97829f7e7a5cf0b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f34aa408d0494848a34f6c5f64d6bfde",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [01:13&lt;00:00, 7.57MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd4e03bd039c466983c76e8bd8d0afe4"
          }
        },
        "e42193319cf1415a851da0b429dd503d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e855c8dbf80428b81d44c6e11a2a026": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f34aa408d0494848a34f6c5f64d6bfde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd4e03bd039c466983c76e8bd8d0afe4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ananya-Jha-code/Injury-Classification-CNN/blob/main/Injury_Classification_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy3RmuVLMzSH"
      },
      "source": [
        "#import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "import cv2\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j66E0mFBoJ-x",
        "outputId": "d5a3d934-7e92-4535-8934-c4e34b7db65c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5w43BgCpmJq",
        "outputId": "f84e08ef-4d13-4ada-cd42-0f8c32e113be"
      },
      "source": [
        "!ls \"/content/drive/MyDrive/injury\""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test  train  valid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zbm1OcJvNgKt"
      },
      "source": [
        "data_dir = '/content/drive/MyDrive/injury'\n",
        "train_dir = '/content/drive/MyDrive/injury/train'\n",
        "valid_dir = '/content/drive/MyDrive/injury/valid'\n",
        "test_dir = '/content/drive/MyDrive/injury/test'"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd9U1x-QN46T"
      },
      "source": [
        "# define transforms for training, validation and test sets\n",
        "training_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                         transforms.RandomResizedCrop(224),\n",
        "                                          transforms.RandomHorizontalFlip(),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize([0.485,0.456,0.406],\n",
        "                                                               [0.229,0.224,0.225])])\n",
        "validation_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                            transforms.CenterCrop(224),\n",
        "                                            transforms.ToTensor(),\n",
        "                                            transforms.Normalize([0.485,0.456,0.406],\n",
        "                                                                 [0.229,0.224,0.225])])\n",
        "testing_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485,0.456,0.406],\n",
        "                                                           [0.229,0.224,0.225])])"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxQGpTYjQDa5"
      },
      "source": [
        "#load datasets with ImageFolder\n",
        "training_dataset = datasets.ImageFolder(train_dir, transform=training_transforms)\n",
        "validation_dataset = datasets.ImageFolder(valid_dir, transform=validation_transforms)\n",
        "testing_dataset = datasets.ImageFolder(test_dir, transform=testing_transforms)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzmIQz_IyzNQ"
      },
      "source": [
        "# define dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=64, shuffle=True)\n",
        "validate_loader = torch.utils.data.DataLoader(validation_dataset,batch_size=32)\n",
        "test_loader = torch.utils.data.DataLoader(testing_dataset,batch_size=32)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRT3uk2-bNfi"
      },
      "source": [
        "def categories(img,injury_type):\n",
        "  return injury_type\n",
        "def make_train_data(injury_type,location):\n",
        "  for img in tqdm(os.listdir(location)):\n",
        "    label = categories(img,injury_type)\n",
        "    path = os.path.join(location,img)\n",
        "    img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
        "    img = cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n",
        "\n",
        "    X.append(np.array(img))\n",
        "    y.append(str(label))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864,
          "referenced_widgets": [
            "917dc8ca599f446b8b0dc167c4291d5b",
            "65e00ba867dc477e9d2c3f1d5639b64a",
            "b4a85e1b17794161a5e1d3c265e64a7c",
            "eed22318adf746ab97829f7e7a5cf0b3",
            "e42193319cf1415a851da0b429dd503d",
            "0e855c8dbf80428b81d44c6e11a2a026",
            "f34aa408d0494848a34f6c5f64d6bfde",
            "fd4e03bd039c466983c76e8bd8d0afe4"
          ]
        },
        "id": "5YuyH-opd0to",
        "outputId": "0972ed3b-2166-4451-cda9-524666e7687f"
      },
      "source": [
        "#build and train network\n",
        "#transfer learning\n",
        "from torchvision import models\n",
        "model = models.vgg16(pretrained=True)\n",
        "model"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "917dc8ca599f446b8b0dc167c4291d5b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C17j_RKOfmv"
      },
      "source": [
        "# no backpropagation on pretrained set to save time\n",
        "for parameter in model.parameters():\n",
        "    parameter.requires_grad = False\n",
        "\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "# Build custom classifier\n",
        "from torch import nn\n",
        "classifier = nn.Sequential(OrderedDict([('fc1',nn.Linear(25088,5000)),\n",
        "                                        ('relu',nn.ReLU()),\n",
        "                                        ('drop',nn.Dropout(p=0.5)),#to avoid overfitting\n",
        "                                        ('fc2',nn.Linear(5000,102)),\n",
        "                                        ('output',nn.LogSoftmax(dim=1))]))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOmh7V1i8r4c"
      },
      "source": [
        "#Function for validation pass\n",
        "def validation (model, validateloader, criterion):\n",
        "  val_loss = 0\n",
        "  accuracy = 0\n",
        "  for images, labels in iter(validateloader):\n",
        "    images, labels = images.to('cuda'), labels.to('cuda')\n",
        "    output = model.forward(images)\n",
        "    val_loss += criterion(output, labels).item()\n",
        "\n",
        "    probabilities = torch.exp(output)\n",
        "    equality = (labels.data == probabilities.max(dim=1)[1])\n",
        "    accuracy += equality.type(torch.FloatTensor).mean()\n",
        "    return val_loss, accuracy"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjpzJxdE944r"
      },
      "source": [
        "#loss function and gradient descent\n",
        "from torch import optim\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PB1J7s0dBGQS",
        "outputId": "5565d1cd-5a4d-4ece-ee8c-beeacb5107ad"
      },
      "source": [
        "import torch\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iEhOJliBd8I",
        "outputId": "2aace082-e755-4cbb-f3ac-a0a165a10aac"
      },
      "source": [
        "pip install workspace"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting workspace\n",
            "  Downloading https://files.pythonhosted.org/packages/12/e7/630da05ab53c1165ef68ae77f3e8332cd48107bdc7869222da3b2c240cb0/workspace-0.3.1.tar.gz\n",
            "Collecting sprinkles>=0.4.4\n",
            "  Downloading https://files.pythonhosted.org/packages/06/db/d8480a6438037f70f598199102801e9ac0b5b9a1c4ef7587a9dd2de4a384/sprinkles-0.4.6.tar.gz\n",
            "Building wheels for collected packages: workspace, sprinkles\n",
            "  Building wheel for workspace (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for workspace: filename=workspace-0.3.1-cp37-none-any.whl size=6188 sha256=121c4e2781f40c3d93f5308b729674c3356e2f1c6c032211cd0a92286ae04cc7\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/ad/78/a8b0e4959544289f25fca64d414165290ba285837b38c07441\n",
            "  Building wheel for sprinkles (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sprinkles: filename=sprinkles-0.4.6-cp37-none-any.whl size=4995 sha256=e8449fba659e5bd6f8e3c3deb47238b476d0d16934271bbf1cf29d5aa5590a23\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/09/fa/e5a0f4b5064e5b6df5f2294039dcf0f414ef82a4a8c66c8d69\n",
            "Successfully built workspace sprinkles\n",
            "Installing collected packages: sprinkles, workspace\n",
            "Successfully installed sprinkles-0.4.6 workspace-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhVGN8NcDbU6",
        "outputId": "6c6fed7f-0998-4468-e859-6741526f1075"
      },
      "source": [
        "pip install utils"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting utils\n",
            "  Downloading https://files.pythonhosted.org/packages/55/e6/c2d2b2703e7debc8b501caae0e6f7ead148fd0faa3c8131292a599930029/utils-1.0.1-py2.py3-none-any.whl\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYXPEeUq3K3G",
        "outputId": "4382e036-932c-4abd-b320-723fb3fd9b52"
      },
      "source": [
        "# Train the classifier\n",
        "\n",
        "\n",
        "def train_classifier():\n",
        "\n",
        "\n",
        "        epochs = 15\n",
        "        steps = 0\n",
        "        print_every = 40\n",
        "\n",
        "        model.to('cuda')\n",
        "\n",
        "        for e in range(epochs):\n",
        "        \n",
        "            model.train()\n",
        "    \n",
        "            running_loss = 0\n",
        "    \n",
        "            for images, labels in iter(train_loader):\n",
        "        \n",
        "                steps += 1\n",
        "        \n",
        "                images, labels = images.to('cuda'), labels.to('cuda')\n",
        "        \n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                output = model.forward(images)\n",
        "                loss = criterion(output, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "        \n",
        "                running_loss += loss.item()\n",
        "        \n",
        "                if steps % print_every == 0:\n",
        "                \n",
        "                    model.eval()\n",
        "                \n",
        "                    # Turn off gradients for validation, saves memory and computations\n",
        "                    with torch.no_grad():\n",
        "                      validation_loss, accuracy = validation(model, validate_loader, criterion)\n",
        "            \n",
        "                    print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "                          \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
        "                          \"Validation Loss: {:.3f}.. \".format(validation_loss/len(validate_loader)),\n",
        "                          \"Validation Accuracy: {:.3f}\".format(accuracy/len(validate_loader)))\n",
        "            \n",
        "                    running_loss = 0\n",
        "                    model.train()\n",
        "                    \n",
        "train_classifier()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2/15..  Training Loss: -773268275.200..  Validation Loss: -1235238707.200..  Validation Accuracy: 0.100\n",
            "Epoch: 3/15..  Training Loss: -1852736409.600..  Validation Loss: -1561016422.400..  Validation Accuracy: 0.100\n",
            "Epoch: 4/15..  Training Loss: -3656838144.000..  Validation Loss: -1936007782.400..  Validation Accuracy: 0.100\n",
            "Epoch: 5/15..  Training Loss: -5658140262.400..  Validation Loss: -2362609254.400..  Validation Accuracy: 0.100\n",
            "Epoch: 6/15..  Training Loss: -8821705164.800..  Validation Loss: -2842926080.000..  Validation Accuracy: 0.100\n",
            "Epoch: 7/15..  Training Loss: -12044110336.000..  Validation Loss: -3376920371.200..  Validation Accuracy: 0.100\n",
            "Epoch: 8/15..  Training Loss: -16860113612.800..  Validation Loss: -3978799923.200..  Validation Accuracy: 0.100\n",
            "Epoch: 9/15..  Training Loss: -22202621747.200..  Validation Loss: -4642648064.000..  Validation Accuracy: 0.100\n",
            "Epoch: 10/15..  Training Loss: -29074581401.600..  Validation Loss: -5364632371.200..  Validation Accuracy: 0.100\n",
            "Epoch: 11/15..  Training Loss: -36690533580.800..  Validation Loss: -6166500147.200..  Validation Accuracy: 0.100\n",
            "Epoch: 12/15..  Training Loss: -46426463232.000..  Validation Loss: -7037730816.000..  Validation Accuracy: 0.100\n",
            "Epoch: 13/15..  Training Loss: -57320365465.600..  Validation Loss: -7964781772.800..  Validation Accuracy: 0.100\n",
            "Epoch: 14/15..  Training Loss: -69591057408.000..  Validation Loss: -8983027712.000..  Validation Accuracy: 0.100\n",
            "Epoch: 15/15..  Training Loss: -84284250521.600..  Validation Loss: -10071790387.200..  Validation Accuracy: 0.100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUz-PncDEYv6",
        "outputId": "1a1448fe-fd35-4928-e8e6-243c743e0611"
      },
      "source": [
        "def test_accuracy(model, test_loader):\n",
        "\n",
        "    # Do validation on the test set\n",
        "    model.eval()\n",
        "    model.to('cuda')\n",
        "\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        accuracy = 0\n",
        "    \n",
        "        for images, labels in iter(test_loader):\n",
        "    \n",
        "            images, labels = images.to('cuda'), labels.to('cuda')\n",
        "    \n",
        "            output = model.forward(images)\n",
        "\n",
        "            probabilities = torch.exp(output)\n",
        "        \n",
        "            equality = (labels.data == probabilities.max(dim=1)[1])\n",
        "        \n",
        "            accuracy += equality.type(torch.FloatTensor).mean()\n",
        "        \n",
        "        print(\"Test Accuracy: {}\".format(accuracy/len(test_loader)))    \n",
        "        \n",
        "        \n",
        "test_accuracy(model, test_loader)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.3125\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}